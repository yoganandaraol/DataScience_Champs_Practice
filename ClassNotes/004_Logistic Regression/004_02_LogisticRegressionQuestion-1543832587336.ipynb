{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/insaid2018/Term-1/blob/master/Images/INSAID_Full%20Logo.png?raw=true\" width=\"240\" height=\"360\" />\n",
    "\n",
    "# ASSIGNMENT\n",
    "# LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##  Bank Marketing\n",
    "\n",
    "\n",
    "**Abstract:** \n",
    "The data is related with __direct marketing campaigns__ (phone calls) of a Portuguese banking institution. The classification goal is to predict if the client will subscribe a __term deposit (variable y)__.\n",
    "\n",
    "**Data Set Information:**\n",
    "The data is related with direct marketing campaigns of a Portuguese banking institution. The marketing campaigns were based on phone calls. Often, more than one contact to the same client was required, in order to access if the __product (bank term deposit)__ would be __('yes')__ or __('no')__ subscribed. \n",
    "\n",
    "###  Source:\n",
    "\n",
    " - Dataset from : http://archive.ics.uci.edu/ml/datasets/Bank+Marketing#\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "bank = pd.read_csv('https://raw.githubusercontent.com/insaid2018/Term-2/master/Data/bank.csv')\n",
    "bank.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the columns present in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the shape of Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the descriptive statistics of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank.describe() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the info of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank.info() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 1. Write a code to understand the below mentioned variables and print their 'unique' attributes.\n",
    "``` ['job', 'marital', 'education', 'housing', 'loan', 'contact', 'month', 'day_of_week', 'campaign','poutcome', 'pdays', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m'] ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log():\n",
    "    # write your code here to print all the unique values of the variables mentioned in question.\n",
    "    # The code output should be user-friendly.\n",
    "    # For eg- Job have these unique values: ['.........']\n",
    "log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 2. Write a code to check the min and max value of age. Also check if there is any null value or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log():\n",
    "    # print the max age\n",
    "    # print the min age\n",
    "    # print the missing values if any\n",
    "log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count of Yes and No for the term deposit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank.y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 3. Write a user defined function to calculate the Inter quartile range for quantile values outside 25 to 75 range. And do the outlier capping for lower level with min value and for upper level with 'q3=1.5*iqr' value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outlier(df_in, col_name):\n",
    "    # Calculate quantile 1 using quantile(0.25)\n",
    "    # Calculate quantile 3\n",
    "    # Calculate IQR as difference of Quantile 3 and quantile 1\n",
    "    # Find the lower bound using the min() function\n",
    "    # Find the upper bound as quantile3 + 1.5*IQR\n",
    "    # Print the lower and upper bound of the column\n",
    "    # Remove the values lying outside min and upper bound range\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 3.1 Using the above created function , remove the outlier from 'age' variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log(bank):\n",
    "    # your code to remove the outlier from age\n",
    "bank = log(bank) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 3.2 Using the above created function , remove the outlier from 'campaign' variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log(bank):\n",
    "    # your code to remove the outlier from campaign\n",
    "bank = log(bank) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 3.3 Using the above created function , remove the outlier from 'duration' variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log(bank):\n",
    "    # your code to remove the outlier from duration\n",
    "bank = log(bank) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividing dataset into two, on the basis of categorical and numerical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_cat=bank[['job', 'marital','default', 'education', 'loan', 'housing', 'contact', 'month', 'day_of_week', 'poutcome', 'y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_cont = bank.drop(['job', 'marital','default', 'education', 'loan', 'housing', 'contact', 'month', 'day_of_week', 'poutcome', 'y'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 4. Label encode the below mentioned categorical variable to numerical values.\n",
    "``` ['job', 'marital','default','education', 'loan', 'housing', 'contact', 'month', 'day_of_week', 'poutcome', 'y'] ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "def log(bank_cat):\n",
    "    # your code to return the value applying fit_transorm\n",
    "bank_cat = log(bank_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining the numerical and categorical dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_final= pd.concat([bank_cont, bank_cat], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 6. Extract independent column to prepare X "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame()\n",
    "def log():\n",
    "    # write your code to create a dataframe of dependent variables excluding 'y' variable\n",
    "    return X\n",
    "X = log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 7. Extract dependent variable into a dataframe 'y' for model predcition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.DataFrame()\n",
    "def log():\n",
    "    # write your code to create a dataframe which consists only of dependepent variable\n",
    "    return y\n",
    "y = log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 8. Splitting X and y intro train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "def log():\n",
    "    return # train test split using train_test_split of 75:25 and random state=1\n",
    "X_train, X_test, y_train, y_test = log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the shape of X an y of train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log():\n",
    "    print(X_train.shape)\n",
    "    print(y_train.shape)\n",
    "log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the shape of X and y of test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log():\n",
    "    print(X_test.shape)\n",
    "    print(y_test.shape)\n",
    "log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 9. Instantitate Logistic Regression model using scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "def log():\n",
    "    # initiate the logistic regression model to new variable logreg\n",
    "    return logreg\n",
    "logreg = log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 10. Fit the logistic model on X_train and y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log():\n",
    "    # fit the X_train and y_train\n",
    "    # We don't expect any return from your side.\n",
    "log()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 11. Using the model for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = pd.DataFrame()\n",
    "def log():\n",
    "    # create the model prediction on X_train data using the above created dataframe\n",
    "    return y_pred_train\n",
    "y_pred_train = log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = pd.DataFrame()\n",
    "def log():\n",
    "    # create the model prediction on X_test data using the above created dataframe\n",
    "    return y_pred_test\n",
    "y_pred_test = log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 12. Model evaluation using accuracy classification score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "def log():\n",
    "    #Calculate and print the accuracy score\n",
    "log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 13. Model evaluation using Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = pd.DataFrame(confusion_matrix(y_test, y_pred_test))\n",
    "def log():\n",
    "    # provide confusion matrix index name as['Actual No_Deposit','Actual Deposit']\n",
    "    # provide confusion matrix index name as['Predicted No_Deposit','Predicted Deposit']\n",
    "    print(confusion_matrix)\n",
    "log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 14. Accuracy prediction setting the threshold = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def log():\n",
    "    # Calculate preds1 keeping the probabilty value as 0.75\n",
    "    # calculate and print the accuracy using the above mentioned threshold probability\n",
    "log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 15. Accuracy prediction setting the threshold = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log():\n",
    "    # Calculate preds2 keeping the probabilty value as 0.25\n",
    "    # calculate and print the accuracy using the above mentioned threshold probability\n",
    "log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
