{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1b6006b",
   "metadata": {},
   "source": [
    "# Summary \n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180d16cb",
   "metadata": {},
   "source": [
    "\n",
    "### Step by step approach\n",
    "\n",
    "`\n",
    "\n",
    "    --- Label encoding ---\n",
    "    from sklearn import preprocessing    ### label_encoder object knows how to understand word labels. \n",
    "    label_encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "    --- Standardize ---- normally applies on dependent variables \n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scalar = StandardScaler().fit(df)\n",
    "\n",
    "    --- Model Creation & Prediction  --- \n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "\n",
    "    lr = LinearRegression(fit_intercept = True)  # instantiate Linear Regression model\n",
    "    model = lr.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "    --- Model Evaluation ---\n",
    "    from sklearn import metrics\n",
    "    from sklearn.metrics import r2_score\n",
    "\n",
    "    MAE = metrics.mean_absolute_error(y_test['charges'], y_pred_df['charges'])\n",
    "    MSE = metrics.mean_squared_error(y_test['charges'], y_pred_df['charges'])\n",
    "    RMSE = np.sqrt(MSE)\n",
    "    R_Sq = r2_score(y_test['charges'], y_pred)\n",
    "\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974d2183",
   "metadata": {},
   "source": [
    "`\n",
    "LinearRegression(\n",
    "    *,\n",
    "    fit_intercept=True,\n",
    "    normalize=False,\n",
    "    copy_X=True,\n",
    "    n_jobs=None,\n",
    "    positive=False,\n",
    ")\n",
    "`\n",
    "\n",
    "* While instantiating linear regression model one of the parameter is __fit_intercept__, which helps in contructing model with y-intercept or not.\n",
    "* __Different slope coefficients__ will be generated, while creating a model with/without `y intercept` \n",
    "\n",
    "\n",
    "equation | fit_intercept\n",
    "--- | ---\n",
    "y = mx + c | LinearRegression()\n",
    "y = mx + c | LinearRegression(fit_intercept = True)\n",
    "y = mx | LinearRegression(fit_intercept = False)\n",
    "\n",
    "\n",
    "* __normalize = True__ sets the mean in the normal destribution to 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec47288",
   "metadata": {},
   "source": [
    "* __n_jobs__ talks about, number of processors required to compute the model\n",
    "\n",
    "\n",
    "    \n",
    "    The number of jobs to use for the computation. This will only provide\n",
    "        speedup for n_targets > 1 and sufficient large problems.\n",
    "        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
    "        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
    "        for more details.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff6249e",
   "metadata": {},
   "source": [
    "    From the implementation point of view, this is just plain Ordinary\n",
    "    Least Squares (scipy.linalg.lstsq) or Non Negative Least Squares\n",
    "    (scipy.optimize.nnls) wrapped as a predictor object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad328b4",
   "metadata": {},
   "source": [
    "* positive : bool, default=False\n",
    "\n",
    "    When set to ``True``, forces the coefficients to be positive. This option is only supported for dense arrays.\n",
    "\n",
    "\n",
    "\n",
    "* Dense Array stores each element in the memory in the exact sequence in which the items are defined, even the item value is undefined.\n",
    "\n",
    "`\n",
    "    Dense is in opposition to sparse, and generally is used when talking about storage. \n",
    "    For example, this array is dense:\n",
    "        a = [undefined, undefined, 2]\n",
    "    It can be stored in memory exactly like that: a sequence of three locations, the first two being undefined, the third being 2.\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ef4849",
   "metadata": {},
   "source": [
    "<hr \\>\n",
    "\n",
    "`\n",
    "LinearRegression(\n",
    "    *,\n",
    "    fit_intercept=True,\n",
    "    normalize=False,\n",
    "    copy_X=True,\n",
    "    n_jobs=None,\n",
    "    positive=False,\n",
    ")\n",
    "`\n",
    "\n",
    "For the hyper-parameter tuning, among the model parameters, `fit_intercept` only influences the model accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce000b0",
   "metadata": {},
   "source": [
    "# Bias and Variance\n",
    "\n",
    "*** Very Important ***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f0d941",
   "metadata": {},
   "source": [
    "* For a model, distribution plot of prediction error should be normally distributed. \n",
    "\n",
    "Observations | Error disribution | Excess Kurtosis ( >3 ) | insights\n",
    "--- |--- | --- | ---\n",
    "1 | normally distributed | No | Best model with less prediction errors\n",
    "2 | skewed  | No | model is biased\n",
    "3 | skewed  | Yes | model is biased and high variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09cfdf4",
   "metadata": {},
   "source": [
    "<img src=\"https://learnopencv.com/wp-content/uploads/2017/02/Bias-Variance-Tradeoff-In-Machine-Learning-1.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b54924",
   "metadata": {},
   "source": [
    "<img src=\"https://community.alteryx.com/t5/image/serverpage/image-id/52874iE986B6E19F3248CF?v=v2\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa062a5",
   "metadata": {},
   "source": [
    "# Kurtosis\n",
    "\n",
    "Kurtosis is a statistical measure that defines how heavily the tails of a distribution differ from the tails of a normal distribution. In other words, kurtosis identifies whether the tails of a given distribution contain extreme values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb9d729",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.corporatefinanceinstitute.com/assets/kurtosis.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff533de",
   "metadata": {},
   "source": [
    "reference - https://corporatefinanceinstitute.com/resources/knowledge/other/kurtosis/\n",
    "\n",
    "\n",
    "\n",
    "## 1. Mesokurtic\n",
    "\n",
    "Data that follows a mesokurtic distribution shows an excess kurtosis of zero or close to zero. This means that if the data follows a normal distribution, it follows a mesokurtic distribution.\n",
    "\n",
    "<img src=\"https://cdn.corporatefinanceinstitute.com/assets/kurtosis1.png\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56d5322",
   "metadata": {},
   "source": [
    "## 2. Leptokurtic\n",
    "\n",
    "Leptokurtic indicates a positive excess kurtosis. The leptokurtic distribution shows heavy tails on either side, indicating large outliers. In finance, a leptokurtic distribution shows that the investment returns may be prone to extreme values on either side. Therefore, an investment whose returns follow a leptokurtic distribution is considered to be risky.\n",
    "\n",
    "<img src=\"https://cdn.corporatefinanceinstitute.com/assets/kurtosis3.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c33d4fd",
   "metadata": {},
   "source": [
    "## 3. Platykurtic\n",
    "\n",
    "A platykurtic distribution shows a negative excess kurtosis. The kurtosis reveals a distribution with flat tails. The flat tails indicate the small outliers in a distribution. In the finance context, the platykurtic distribution of the investment returns is desirable for investors because there is a small probability that the investment would experience extreme returns.\n",
    "\n",
    "<img src=\"https://cdn.corporatefinanceinstitute.com/assets/kurtosis2.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4fb449",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
